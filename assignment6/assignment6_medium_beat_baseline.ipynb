{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\" />\n",
    "    \n",
    "## [mlcourse.ai](https://mlcourse.ai) â€“ Open Machine Learning Course \n",
    "Author: [Yury Kashnitskiy](https://yorko.github.io) (@yorko). Edited by Sergey Kolchenko (@KolchenkoSergey). This material is subject to the terms and conditions of the [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license. Free use is permitted for any non-commercial purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Assignment #6\n",
    "### <center> Beating baselines in \"How good is your Medium article?\"\n",
    "    \n",
    "<img src='../../img/medium_claps.jpg' width=40% />\n",
    "\n",
    "\n",
    "[Competition](https://www.kaggle.com/c/how-good-is-your-medium-article). The task is to beat \"A6 baseline\" (~1.45 Public LB score). Do not forget about our shared [\"primitive\" baseline](https://www.kaggle.com/kashnitsky/ridge-countvectorizer-baseline) - you'll find something valuable there.\n",
    "\n",
    "**Your task:**\n",
    " 1. \"Freeride\". Come up with good features to beat the baseline \"A6 baseline\" (for now, public LB is only considered)\n",
    " 2. You need to name your [team](https://www.kaggle.com/c/how-good-is-your-medium-article/team) (out of 1 person) in full accordance with the [course rating](https://drive.google.com/open?id=19AGEhUQUol6_kNLKSzBsjcGUU3qWy3BNUg8x8IFkO3Q). You can think of it as a part of the assignment. 16 credits for beating the mentioned baseline and correct team naming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy.sparse import csr_matrix, hstack,coo_matrix\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will help to throw away all HTML tags from an article content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser\n",
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs= True\n",
    "        self.fed = []\n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "    def get_data(self):\n",
    "        return ''.join(self.fed)\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supplementary function to read a JSON line without crashing on escape characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_line(line=None):\n",
    "    result = None\n",
    "    try:        \n",
    "        result = json.loads(line)\n",
    "    except Exception as e:      \n",
    "        # Find the offending character index:\n",
    "        idx_to_replace = int(str(e).split(' ')[-1].replace(')',''))      \n",
    "        # Remove the offending character:\n",
    "        new_line = list(line)\n",
    "        new_line[idx_to_replace] = ' '\n",
    "        new_line = ''.join(new_line)     \n",
    "        return read_json_line(line=new_line)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features `content`, `published`, `title` and `author`, write them to separate files for train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_features_and_write(path_to_data,\n",
    "#                                inp_filename, is_train=True):\n",
    "    \n",
    "#     features = ['content', 'published', 'title', 'author', 'domain', 'tags']\n",
    "#     prefix = 'train' if is_train else 'test'\n",
    "#     feature_files = [open(os.path.join(path_to_data,\n",
    "#                                        '{}_{}.txt'.format(prefix, feat)),\n",
    "#                           'w', encoding='utf-8')\n",
    "#                      for feat in features]\n",
    "    \n",
    "#     with open(os.path.join(path_to_data, inp_filename), \n",
    "#               encoding='utf-8') as inp_json_file:\n",
    "        \n",
    "\n",
    "#         for line in tqdm_notebook(inp_json_file):\n",
    "#             json_data = read_json_line(line)\n",
    "            \n",
    "#             print(json_data)\n",
    "            \n",
    "#             content = json_data['content'].replace('\\n',' ').replace('\\r',' ')\n",
    "#             feature_files[0].write(strip_tags(content)+'\\n')\n",
    "            \n",
    "#             feature_files[1].write(json_data['published']['$date']+'\\n')\n",
    "            \n",
    "#             feature_files[2].write(strip_tags(json_data['title']).split('\\u2013')[0].strip().replace('\\n',' ').replace('\\r',' ')+'\\n')\n",
    "            \n",
    "#             feature_files[3].write(json_data['meta_tags']['author'].strip()+'\\n')\n",
    "            \n",
    "#             feature_files[4].write(json_data['domain']+'\\n')\n",
    "            \n",
    "#             tags_str = []\n",
    "#             soup = BeautifulSoup(content, 'lxml')\n",
    "#             try:\n",
    "#                 tag_block = soup.find('ul', class_='tags')\n",
    "#                 tags = tag_block.find_all('a')\n",
    "#                 for tag in tags:\n",
    "#                     tags_str.append(tag.text.translate({ord(' '):None, ord('-'):None}))\n",
    "#                 tags = ' '.join(tags_str)\n",
    "#             except Exception:\n",
    "#                 tags = 'None'\n",
    "            \n",
    "#             feature_files[5].write(tags+'\\n')\n",
    "\n",
    "#         for feature_file in feature_files:\n",
    "#             feature_file.close()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_and_write(path_to_data,\n",
    "                               inp_filename, is_train=True):  \n",
    "            \n",
    "    content_list = []\n",
    "    published_list =[]\n",
    "    title_list =[]\n",
    "    author_list =[]\n",
    "    domain_list =[]\n",
    "    tags_list = []\n",
    "    \n",
    "\n",
    "    with open(os.path.join(path_to_data, inp_filename), \n",
    "              encoding='utf-8') as inp_json_file:\n",
    "        \n",
    "        for line in tqdm_notebook(inp_json_file):\n",
    "            json_data = read_json_line(line)\n",
    "            \n",
    "            \n",
    "#             content = json_data['content'].replace('\\n',' ').replace('\\r',' ')\n",
    "#             content_list.append(strip_tags(content))\n",
    "            \n",
    "            published_list.append(json_data['published']['$date'])\n",
    "            \n",
    "#             title_list.append(strip_tags(json_data['title']).split('\\u2013')[0].strip().replace('\\n',' ').replace('\\r',' '))\n",
    "            title_list.append(strip_tags(json_data['title']).replace('\\n',' ').replace('\\r',' '))\n",
    "            \n",
    "#             author_list.append(json_data['meta_tags']['author'].strip())\n",
    "            \n",
    "#             domain_list.append(json_data['domain'])\n",
    "            \n",
    "#             tags_str = []\n",
    "#             soup = BeautifulSoup(content, 'lxml')\n",
    "#             try:\n",
    "#                 tag_block = soup.find('ul', class_='tags')\n",
    "#                 tags = tag_block.find_all('a')\n",
    "#                 for tag in tags:\n",
    "#                     tags_str.append(tag.text.translate({ord(' '):None, ord('-'):None}))\n",
    "#                 tags = ' '.join(tags_str)\n",
    "#             except Exception:\n",
    "#                 tags = 'None'\n",
    "            \n",
    "#             tags_list.append(tags)\n",
    "            \n",
    "        df = pd.DataFrame()\n",
    "#         df['content'] = content_list\n",
    "        df['published'] = pd.to_datetime(published_list, format='%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "        df['title'] = title_list\n",
    "#         df['author'] = author_list\n",
    "#         df['domain'] = domain_list\n",
    "#         df['tags'] = tags_list\n",
    "        \n",
    "        df.sort_values(by ='published',inplace=True)\n",
    "\n",
    "#         features = ['content', 'published', 'title', 'author', 'domain', 'tags']\n",
    "        features = ['title']\n",
    "\n",
    "    \n",
    "        prefix = 'train' if is_train else 'test'\n",
    "        \n",
    "        for feat in features:\n",
    "            df[feat].to_csv(os.path.join(path_to_data,'{}_{}.txt'.format(prefix, feat)),sep=' ',index=None,header =None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = '../data/Medium' # modify this if you need to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_features_and_write(PATH_TO_DATA, 'train.json', is_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ef9505de1954ce7887da9b31befa18a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "extract_features_and_write(PATH_TO_DATA, 'test.json', is_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add the following groups of features:**\n",
    "    - Tf-Idf with article content (ngram_range=(1, 2), max_features=100000 but you can try adding more)\n",
    "    - Tf-Idf with article titles (ngram_range=(1, 2), max_features=100000 but you can try adding more)\n",
    "    - Time features: publication hour, whether it's morning, day, night, whether it's a weekend\n",
    "    - Bag of authors (i.e. One-Hot-Encoded author names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_content = TfidfVectorizer(ngram_range=(1,2),max_features=100000)\n",
    "\n",
    "with open(os.path.join(PATH_TO_DATA,'train_content.txt'),encoding=\"utf8\") as train_content:\n",
    "    X_train_content_sparse = tfidf_content.fit_transform(train_content)\n",
    "    \n",
    "with open(os.path.join(PATH_TO_DATA,'test_content.txt'),encoding=\"utf8\") as test_content:\n",
    "    X_test_content_sparse = tfidf_content.transform(test_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((62313, 50000), (34645, 50000))"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_content_sparse.shape,X_test_content_sparse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_title = TfidfVectorizer(ngram_range=(1,2),max_features=100000\n",
    "\n",
    "with open(os.path.join(PATH_TO_DATA,'train_title.txt'),encoding=\"utf8\") as train_title:\n",
    "    X_train_title_sparse = tfidf_title.fit_transform(train_title)\n",
    "    \n",
    "with open(os.path.join(PATH_TO_DATA,'test_title.txt'),encoding=\"utf8\") as test_title:\n",
    "    X_test_title_sparse = tfidf_title.transform(test_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((62313, 50000), (34645, 50000))"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_title_sparse.shape,X_test_title_sparse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "# sparse.save_npz(\"./data/medium/X_test_content_sparse.npz\", X_test_content_sparse)\n",
    "X_test_content_sparse = sparse.load_npz(\"./data/medium/X_test_content_sparse.npz\")\n",
    "\n",
    "# sparse.save_npz(\"./data/medium/X_train_content_sparse.npz\", X_train_content_sparse)\n",
    "X_train_content_sparse = sparse.load_npz(\"./data/medium/X_train_content_sparse.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_author_ = pd.read_csv(os.path.join(PATH_TO_DATA,'train_author.txt'),header=None,usecols=[0],)\n",
    "test_author_ = pd.read_csv(os.path.join(PATH_TO_DATA,'test_author.txt'),header=None,usecols=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = pd.concat([train_author_,test_author_],axis=0,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LE = LabelEncoder()\n",
    "LE.fit(authors)\n",
    "X_train_author_LE = LE.transform(train_author_)\n",
    "X_test_author_LE  = LE.transform(test_author_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features='all', dtype=<class 'numpy.float64'>,\n",
       "       handle_unknown='ignore', n_values='auto', sparse=True)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OHE = OneHotEncoder(handle_unknown='ignore')\n",
    "OHE.fit(X_train_author_LE.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_author_sparse = OHE.transform(X_train_author_LE.reshape(-1,1))\n",
    "X_test_author_sparse  = OHE.transform(X_test_author_LE.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((62313, 31331), (34645, 31331))"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_author_sparse.shape, X_test_author_sparse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# authors = pd.concat([train_author_,test_author_],axis=0,sort=False)\n",
    "# authors = pd.get_dummies(authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_author_sparse = authors.iloc[:train_author_.shape[0],]\n",
    "# X_test_author_sparse = authors.iloc[train_author_.shape[0]:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((62313, 43885), (34645, 43885))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train_author_sparse.shape, X_test_author_sparse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_time = pd.read_csv(os.path.join(PATH_TO_DATA,'train_published.txt'),header=None,names=['date'],\n",
    "                                            parse_dates =['date'])\n",
    "X_test_time = pd.read_csv(os.path.join(PATH_TO_DATA,'test_published.txt'),header=None,names=['date'],\n",
    "                                         parse_dates =['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((62313, 1), (34645, 1))"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_time.shape,X_test_time.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_features(df):\n",
    "    new_df = pd.DataFrame(index=df.index)\n",
    "    hour = df['date'].apply(lambda ts: ts.hour)\n",
    "    new_df['morning'] = ((hour >= 7) & (hour <= 11)).astype('int')\n",
    "    new_df[\"day\"] = ((hour >= 12) & (hour <= 18)).astype('int')\n",
    "    new_df[\"evening\"] = ((hour >= 19) & (hour <= 23)).astype('int')\n",
    "    new_df[\"night\"] = ((hour >= 0) & (hour <= 6)).astype('int')\n",
    "#     new_df['is_weekend'] = df['date'].dt.weekday.isin([6,7]).astype('int')\n",
    "    new_df['year'] = df['date'].dt.year\n",
    "    new_df['month'] = df['date'].dt.month\n",
    "    new_df['weekday'] = df['date'].dt.weekday\n",
    "#     new_df['hour'] = df['date'].dt.hour    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_time_features_sparse = add_time_features(X_train_time)\n",
    "X_test_time_features_sparse = add_time_features(X_test_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62313, 7)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_time_features_sparse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>morning</th>\n",
       "      <th>day</th>\n",
       "      <th>evening</th>\n",
       "      <th>night</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1970</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1970</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1970</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   morning  day  evening  night  year  month  weekday\n",
       "0        0    0        0      1  1970      1        3\n",
       "1        0    0        0      1  1970      1        3\n",
       "2        0    0        0      1  1970      1        6\n",
       "3        0    0        1      0  1987     12        1\n",
       "4        0    1        0      0  2003     12        0"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_time_features_sparse.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(PATH_TO_DATA,'train_content.txt'),encoding=\"utf8\") as train_content:\n",
    "    length =[] \n",
    "    for line in train_content:\n",
    "        length.append(len(line))\n",
    "X_train_time_features_sparse['length'] = length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(PATH_TO_DATA,'test_content.txt'),encoding=\"utf8\") as test_content:\n",
    "    length =[] \n",
    "    for line in test_content:\n",
    "        length.append(len(line))\n",
    "X_test_time_features_sparse['length'] = length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(PATH_TO_DATA,'train_tags.txt'),encoding=\"utf8\") as train_tags:\n",
    "    length =[] \n",
    "    for line in train_tags:\n",
    "        length.append(len(line))\n",
    "X_train_time_features_sparse['tag_length'] = length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(PATH_TO_DATA,'test_tags.txt'),encoding=\"utf8\") as test_tags:\n",
    "    length =[] \n",
    "    for line in test_tags:\n",
    "        length.append(len(line))\n",
    "X_test_time_features_sparse['tag_length'] = length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>morning</th>\n",
       "      <th>day</th>\n",
       "      <th>evening</th>\n",
       "      <th>night</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "      <th>length</th>\n",
       "      <th>tag_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1970</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5476</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1970</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5328</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1970</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2490</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>11288</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>12544</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   morning  day  evening  night  year  month  weekday  length  tag_length\n",
       "0        0    0        0      1  1970      1        3    5476          52\n",
       "1        0    0        0      1  1970      1        3    5328           3\n",
       "2        0    0        0      1  1970      1        6    2490          14\n",
       "3        0    0        1      0  1987     12        1   11288          48\n",
       "4        0    1        0      0  2003     12        0   12544          18"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_time_features_sparse.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>morning</th>\n",
       "      <th>day</th>\n",
       "      <th>evening</th>\n",
       "      <th>night</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "      <th>length</th>\n",
       "      <th>tag_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7615</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6822</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>14447</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>13626</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>15074</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   morning  day  evening  night  year  month  weekday  length  tag_length\n",
       "0        0    0        0      1  2017      7        5    7615          62\n",
       "1        0    0        0      1  2017      7        5    6822          82\n",
       "2        0    0        0      1  2017      7        5   14447          52\n",
       "3        0    0        0      1  2017      7        5   13626          44\n",
       "4        0    0        0      1  2017      7        5   15074          46"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_time_features_sparse.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "minmax = MinMaxScaler()\n",
    "minmax.fit(X_train_time_features_sparse)\n",
    "X_train_time_features_sparse_norm =minmax.transform(X_train_time_features_sparse)\n",
    "X_test_time_features_sparse_norm =minmax.transform(X_test_time_features_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Join all sparse matrices.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sparse = hstack([X_train_content_sparse, X_train_title_sparse,\n",
    "                         X_train_author_sparse, \n",
    "                         X_train_time_features_sparse_norm]).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62313, 131340)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sparse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sparse = hstack([X_test_content_sparse, X_test_title_sparse,\n",
    "                        X_test_author_sparse, \n",
    "                        X_test_time_features_sparse_norm]).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "# sparse.save_npz(\"./data/medium/X_train_sparse.npz\", X_train_sparse)\n",
    "X_train_sparse = sparse.load_npz(\"./data/medium/X_train_sparse.npz\")\n",
    "\n",
    "# sparse.save_npz(\"./data/medium/X_test_sparse.npz\", X_test_sparse)\n",
    "X_test_sparse = sparse.load_npz(\"./data/medium/X_test_sparse.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read train target and split data for validation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = pd.read_csv(os.path.join(PATH_TO_DATA, 'train_log1p_recommends.csv'), \n",
    "                           index_col='id')\n",
    "y_train = train_target['log_recommends'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_part_size = int(0.7 * train_target.shape[0])\n",
    "X_train_part_sparse = X_train_sparse[:train_part_size, :]\n",
    "y_train_part = y_train[:train_part_size]\n",
    "X_valid_sparse =  X_train_sparse[train_part_size:, :]\n",
    "y_valid = y_train[train_part_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train a simple Ridge model and check MAE on the validation set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lridge = Ridge(random_state=17)\n",
    "lridge.fit(X_train_part_sparse,y_train_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.622917412171956"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_valid,lridge.predict(X_valid_sparse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.622813180558879"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_valid,lridge.predict(X_valid_sparse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0903316131971577"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_valid,lridge.predict(X_valid_sparse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0736315005313009"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_valid,lridge.predict(X_valid_sparse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the same Ridge with all available data, make predictions for the test set and form a submission file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34645, 244250)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_sparse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lridge.fit(X_train_sparse,y_train)\n",
    "prediction = lridge.predict(X_test_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_submission_file(prediction, filename,\n",
    "                          path_to_sample=os.path.join(PATH_TO_DATA, \n",
    "                                                      'sample_submission.csv')):\n",
    "    submission = pd.read_csv(path_to_sample, index_col='id')\n",
    "    \n",
    "    submission['log_recommends'] = prediction\n",
    "    submission.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3605271917129667"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.mean()#1.45082"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9727528082870336"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4.33328-2.3605271917129667"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_adjusted = prediction+ 1.9727528082870336"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.33328"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_adjusted.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission_file(prediction_adjusted, './assignment6_submissions/assignment6_medium_submission_adjusted.csv')#1.66273"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission_file(prediction, './assignment6_submissions/assignment6_medium_submission_default.csv') #2.33484"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now's the time for dirty Kaggle hacks. Form a submission file with all zeroes. Make a submission. What do you get if you think about it? How is it going to help you with modifying your predictions?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission_file(np.zeros_like(prediction), './assignment6_submissions/medium_all_zeros_submission.csv')#LB 4.33328"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modify predictions in an appropriate way (based on your all-zero submission) and make a new submission.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_test_pred_modif = ridge_test_pred # You code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission_file(ridge_test_pred_modif, \n",
    "                      os.path.join(PATH_TO_DATA,\n",
    "                                   'assignment6_medium_submission_with_hack.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ts = TimeSeriesSplit(5)\n",
    "alphas = np.logspace(-1,2,5)\n",
    "lridgeCV = RidgeCV(alphas=alphas, scoring ='neg_mean_absolute_error',cv=ts)\n",
    "lridgeCV.fit(X_train_sparse,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lridgeCV.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lridge = Ridge(random_state=17,alpha=100)\n",
    "lridge.fit(X_train_part_sparse,y_train_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.493027351276218"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_valid,lridge.predict(X_valid_sparse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 34.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lridge.fit(X_train_sparse,y_train)\n",
    "prediction = lridge.predict(X_test_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0148218378784315"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_adjusted = prediction+ (4.33328 -prediction.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission_file(pred_adjusted, './assignment6_submissions/assignment6_medium_submission_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lasreg = Lasso(random_state=17)\n",
    "lasreg.fit(X_train_part_sparse,y_train_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4881453048830608"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_valid,lasreg.predict(X_valid_sparse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..................................................[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ts = TimeSeriesSplit(5)\n",
    "alphas = np.logspace(-1,4,10)\n",
    "lasregCV = LassoCV(alphas=alphas,cv=ts,n_jobs=-1,verbose=True)\n",
    "lasregCV.fit(X_train_sparse,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000.0"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasregCV.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lasreg = Lasso(random_state=17,alpha=1000000)\n",
    "lasreg.fit(X_train_part_sparse,y_train_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4881453048830608"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_valid,lasreg.predict(X_valid_sparse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it for the assignment. Much more credits will be given to the winners in this competition, check [course roadmap](https://mlcourse.ai/roadmap). Do not spoil the assignment and the competition - don't share high-performing kernels (with MAE < 1.5).\n",
    "\n",
    "Some ideas for improvement:\n",
    "\n",
    "- Engineer good features, this is the key to success. Some simple features will be based on publication time, authors, content length and so on\n",
    "- You may not ignore HTML and extract some features from there\n",
    "- You'd better experiment with your validation scheme. You should see a correlation between your local improvements and LB score\n",
    "- Try TF-IDF, ngrams, Word2Vec and GloVe embeddings\n",
    "- Try various NLP techniques like stemming and lemmatization\n",
    "- Tune hyperparameters. In our example, we've left only 50k features and used C=1 as a regularization parameter, this can be changed\n",
    "- SGD and Vowpal Wabbit will learn much faster\n",
    "- Play around with blending and/or stacking. An intro is given in [this Kernel](https://www.kaggle.com/kashnitsky/ridge-and-lightgbm-simple-blending) by @yorko \n",
    "- In our course, we don't cover neural nets. But it's not obliged to use GRUs/LSTMs/whatever in this competition.\n",
    "\n",
    "Good luck!\n",
    "\n",
    "<img src='../../img/kaggle_shakeup.png' width=50%>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
